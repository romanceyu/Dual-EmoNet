import os

import cv2
import torch
import numpy as np
import torch.nn.functional as F
from torchvision import transforms
import matplotlib.pyplot as plt
from PIL import Image


device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

from approach.DA_EmoNet2 import ImprovedResEmoteNet

# -------------------- é€‰æ‹©æ¨¡å‹æ–‡ä»¶ --------------------
MODEL_DIR = "/root/autodl-tmp/ResEmoteNet/runs/20250312-202814/models"
MODEL_FILE = "best_test_model.pth"  # ğŸ”´ ä½ å¯ä»¥æ”¹æˆ "val.pth" æ¥åŠ è½½å¦ä¸€ä¸ªæ¨¡å‹

model_path = os.path.join(MODEL_DIR, MODEL_FILE)
if not os.path.exists(model_path):
    raise FileNotFoundError(f"âŒ æ¨¡å‹æ–‡ä»¶ {model_path} ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥è·¯å¾„ï¼")

print(f"âœ… åŠ è½½æ¨¡å‹: {model_path}")
# -------------------- åŠ è½½æ¨¡å‹ --------------------
model = ImprovedResEmoteNet().to(device)  # åˆ›å»ºæ¨¡å‹å®ä¾‹å¹¶ç§»è‡³æŒ‡å®šè®¾å¤‡
checkpoint = torch.load(model_path, map_location=device)  # åŠ è½½æ¨¡å‹æƒé‡
model.load_state_dict(checkpoint['model_state_dict'])  # åŠ è½½æ¨¡å‹å‚æ•°
model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
img_path = '/root/autodl-tmp/ResEmoteNet/attention/test_1404_aligned_anger.jpg'

# å¦‚æœéœ€è¦ï¼Œå¯ä»¥ç›´æ¥ç”¨ PIL æ‰“å¼€å›¾åƒï¼ˆä½†ä¸‹é¢çš„å‡½æ•°ä¸­ä¼šç”¨ cv2 è¯»å–ï¼‰
img = Image.open(img_path)
img = np.array(img)  # å˜ä¸º (H, W, C) å½¢çŠ¶çš„ NumPy æ•°ç»„
def process_image(image_path):
    preprocess = transforms.Compose([
        transforms.ToPILImage(),  # å°† OpenCV çš„ numpy æ•°ç»„è½¬æ¢ä¸º PIL å›¾åƒ
        transforms.Resize((64, 64)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    # ä½¿ç”¨ä¼ å…¥çš„ image_pathï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç çš„ img_path
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"æ— æ³•åŠ è½½å›¾åƒ: {image_path}")
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = preprocess(img).unsqueeze(0)
    return img

from hook import Hook

final_layer = model.conv3
hook = Hook()
hook.register_hook(final_layer)

img_tensor = process_image(img_path).to(device)

logits = model(img_tensor)
probabilities = F.softmax(logits, dim=1)
predicted_class = torch.argmax(probabilities, dim=1)

predicted_class_idx = predicted_class.item()
print(f'Predicted class: {predicted_class_idx}')

one_hot_output = torch.FloatTensor(1, probabilities.shape[1]).zero_().to(device)
one_hot_output[0][predicted_class_idx] = 1
logits.backward(one_hot_output, retain_graph=True)

gradients = hook.backward_out
feature_maps = hook.forward_out

hook.unregister_hook()

weights = torch.mean(gradients, dim=[2, 3], keepdim=True)
cam = torch.sum(weights * feature_maps, dim=1, keepdim=True)
cam = cam.clamp(min=0).squeeze()

cam -= cam.min()
cam /= cam.max()
cam = cam.cpu().detach().numpy()
cam = cv2.resize(cam, (64, 64))

heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_VIRIDIS)
heatmap = np.float32(heatmap) / 255

# è°ƒæ•´åŸå§‹å›¾åƒå°ºå¯¸ï¼Œä½¿å…¶ä¸çƒ­åŠ›å›¾ä¸€è‡´
img_resized = cv2.resize(img, (64, 64))
superimposed_img = heatmap * 0.5 + np.float32(img_resized) / 255
superimposed_img = cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)
superimposed_img = np.clip(superimposed_img * 255, 0, 255).astype(np.uint8)  # é™åˆ¶åˆ° 0-255 å¹¶è½¬æ¢ä¸º uint8



plt.figure(figsize=(18, 6))

plt.subplot(1, 3, 1)
plt.imshow(img)
plt.axis('off')
plt.legend('åŸå›¾')

plt.subplot(1, 3, 2)

cax = plt.matshow(cam, cmap='viridis', fignum=0)
plt.axis('off')
plt.colorbar(cax, ax=plt.gca(), fraction=0.045, pad=0.05)
plt.legend('heatmap')
# superimposed = cv2.addWeighted(
#                 cv2.cvtColor(superimposed_img, cv2.COLOR_RGB2BGR), 0.5,  # åŸå›¾å æ¯”30%
#                 heatmap, 0.5,  # çƒ­åŠ›å›¾å æ¯”70%
#                 0  # äº®åº¦è°ƒèŠ‚
#             )

plt.subplot(1, 3, 3)
plt.imshow(superimposed_img)
plt.axis('off')
plt.legend('å åŠ å')

plt.savefig('gcam_anger.png', dpi=400, bbox_inches='tight', pad_inches=0.1)
plt.show()

# å®šä¹‰ä¿å­˜è·¯å¾„
output_dir = "/root/autodl-tmp/ResEmoteNet/attention"
filename = "anger.png"
save_path = os.path.join(output_dir, filename)

# ç¡®ä¿ç›®å½•å­˜åœ¨
if not os.path.exists(output_dir):
    os.makedirs(output_dir)
# ä¿å­˜å›¾åƒ
# ä¿å­˜é«˜æ¸…å›¾åƒ
plt.savefig(save_path, dpi=400, bbox_inches='tight', pad_inches=0.1)

# æ˜¾ç¤ºå›¾åƒ
plt.show()